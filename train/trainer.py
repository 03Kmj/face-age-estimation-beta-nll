# import argparse
# import torch
# from torch.utils.data import DataLoader
# from torch.utils.tensorboard import SummaryWriter
# import sys, os, time
# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # í”„ë¡œì íŠ¸ ìµœìƒìœ„ ê²½ë¡œ import ìœ„í•´ ì¶”ê°€

# from config import Config
# from data.dataset import DeepfakeDataset
# from models.model import BetaNLL_AgePredictor
# from models.losses import Beta_NLL_Loss
# from train.train_utils import train_one_epoch, validate, save_checkpoint


# # -------------------------------------------
# # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì„¤ì •
# # python train/trainer.py --model beta_nll --epochs 30 --batch_size 32
# # -------------------------------------------

# def parse_args():
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--model", type=str, choices=["beta_nll", "mse"], default="beta_nll")
#     parser.add_argument("--epochs", type=int, default=Config.EPOCHS)
#     parser.add_argument("--batch_size", type=int, default=Config.BATCH_SIZE)
#     parser.add_argument("--lr", type=float, default=Config.LR)
#     parser.add_argument("--num_workers", type=int, default=Config.NUM_WORKERS)
#     return parser.parse_args()


# # ---------------------------
# # ì‹œê°„ í¬ë§· í•¨ìˆ˜
# # ---------------------------
# def format_time(seconds):
#     m, s = divmod(int(seconds), 60)
#     h, m = divmod(m, 60)
#     if h > 0:
#         return f"{h}ì‹œê°„ {m}ë¶„ {s}ì´ˆ"
#     elif m > 0:
#         return f"{m}ë¶„ {s}ì´ˆ"
#     else:
#         return f"{s}ì´ˆ"


# def main():
#     args = parse_args()
    
#     # print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!ë”¥í˜ì´í¬ íƒì§€ ì‹œì‘(small ë²„ì „)-> .env íŒŒì¼ì—ì„œ ê²½ë¡œ ìˆ˜ì •!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    
#     print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!ë”¥í˜ì´í¬ íƒì§€ ì‹œì‘!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    

#     # --------------------------
#     # Device ì„¤ì •
#     # --------------------------
#     if torch.backends.mps.is_available():
#         device = torch.device("mps")
#         print("âœ… Apple Silicon GPU (MPS)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
#         print("ğŸ”¥ Running trainer.py at:", __file__)

#     elif torch.cuda.is_available():
#         device = torch.device("cuda")
#         print("ğŸš€ NVIDIA GPU(CUDA)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
#     else:
#         device = torch.device("cpu")
#         print("âš ï¸ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. GPU ê°€ì† ì—†ìŒ.")

#     # -------------------------------------------
#     # Dataset ë° DataLoader êµ¬ì„±
#     # DeepfakeDataset: real / fake / subset(train/val/test)
#     # -------------------------------------------
#     train_dataset = DeepfakeDataset(Config.DATA_DIR, subset='train')
#     val_dataset   = DeepfakeDataset(Config.DATA_DIR, subset='val')

#     train_loader = DataLoader(
#         train_dataset, batch_size=args.batch_size, shuffle=True,
#         num_workers=args.num_workers
#     )

#     val_loader = DataLoader(
#         val_dataset, batch_size=args.batch_size, shuffle=False,
#         num_workers=args.num_workers
#     ) 

#     # --------------------------
#     # ëª¨ë¸ ì„ íƒ
#     # --------------------------
#     if args.model == "beta_nll":
#         model = BetaNLL_AgePredictor().to(device)
#         criterion = Beta_NLL_Loss()
#     else:
#         raise NotImplementedError("MSE ëª¨ë¸ì€ ì•„ì§ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

#     # TensorBoard ì„¤ì •
#     writer = SummaryWriter(f"{Config.LOG_DIR}/{args.model}")

#     best_loss = float("inf")

#     # --------------------------
#     # Training Loop
#     # --------------------------
    
#     total_epochs = args.epochs
#     epoch_times = []
#     for epoch in range(args.epochs):
#         print(f"\n[Epoch {epoch+1}/{args.epochs}]")

#         epoch_start = time.time()   # <-- ì‹œì‘ ì‹œê°„ ì¸¡ì •

#         train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)
#         val_loss, val_mae = validate(model, val_loader, criterion, device)
        
        
        
#         # --------------------------
#         # Epoch ì¢…ë£Œ â†’ ì‹œê°„ ê³„ì‚°
#         # --------------------------
#         epoch_time = time.time() - epoch_start
#         epoch_times.append(epoch_time)

#         print(f"â±ï¸ ì´ë²ˆ Epoch ì†Œìš” ì‹œê°„: {format_time(epoch_time)}")

#         # --------------------------
#         # ETA ê³„ì‚° (í‰ê·  ì‹œê°„ ê¸°ë°˜)
#         # --------------------------
#         avg_time = sum(epoch_times) / len(epoch_times)
#         remaining_epochs = total_epochs - (epoch + 1)
#         eta = remaining_epochs * avg_time

#         print(f"ğŸ”® ì˜ˆìƒ ë‚¨ì€ ì‹œê°„(ETA): {format_time(eta)}")

#         # --------------------------
#         # ë¡œê·¸ ì¶œë ¥
#         # --------------------------
#         print(f"Train Loss: {train_loss:.4f}")
#         print(f"Val Loss:   {val_loss:.4f}")
#         print(f"Val MAE:    {val_mae:.4f}")
        
#         # TensorBoard ê¸°ë¡
#         writer.add_scalar("Loss/train", train_loss, epoch)
#         writer.add_scalar("Loss/val", val_loss, epoch)
#         writer.add_scalar("MAE/val", val_mae, epoch)

#         # --------------------------
#         # Best Model ì €ì¥
#         # --------------------------
#         if val_loss < best_loss:
#             best_loss = val_loss
#             save_path = f"models/best_{args.model}_model.pth"
#             save_checkpoint(model, save_path)

#     writer.close()
#     print("\n[Training Completed]")


# if __name__ == "__main__":
#     main()


import argparse
import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import torch.nn as nn
import sys, os, time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # í”„ë¡œì íŠ¸ ìµœìƒìœ„ ê²½ë¡œ import ìœ„í•´ ì¶”ê°€

from config import Config
from data.dataset import DeepfakeDataset
from models.model import DeepfakeUncertaintyModel
from models.losses import Beta_NLL_Loss
from train.train_utils import train_one_epoch, validate, save_checkpoint


# -------------------------------------------
# ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì„¤ì •
# python train/trainer.py --model beta_nll --epochs 30 --batch_size 32
# -------------------------------------------

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, choices=["beta_nll", "mse"], default="beta_nll")
    parser.add_argument("--epochs", type=int, default=Config.EPOCHS)
    parser.add_argument("--batch_size", type=int, default=Config.BATCH_SIZE)
    parser.add_argument("--lr", type=float, default=Config.LR)
    parser.add_argument("--num_workers", type=int, default=Config.NUM_WORKERS)
    return parser.parse_args()


# ---------------------------
# ì‹œê°„ í¬ë§· í•¨ìˆ˜
# ---------------------------
def format_time(seconds):
    m, s = divmod(int(seconds), 60)
    h, m = divmod(m, 60)
    if h > 0:
        return f"{h}ì‹œê°„ {m}ë¶„ {s}ì´ˆ"
    elif m > 0:
        return f"{m}ë¶„ {s}ì´ˆ"
    else:
        return f"{s}ì´ˆ"


def main():
    args = parse_args()
    
    # print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!ë”¥í˜ì´í¬ íƒì§€ ì‹œì‘(small ë²„ì „)-> .env íŒŒì¼ì—ì„œ ê²½ë¡œ ìˆ˜ì •!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    
    print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!ë”¥í˜ì´í¬ íƒì§€ ì‹œì‘!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    

    # --------------------------
    # Device ì„¤ì •
    # --------------------------
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… Apple Silicon GPU (MPS)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print("ğŸ”¥ Running trainer.py at:", __file__)

    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ NVIDIA GPU(CUDA)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        device = torch.device("cpu")
        print("âš ï¸ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. GPU ê°€ì† ì—†ìŒ.")

    # -------------------------------------------
    # Dataset ë° DataLoader êµ¬ì„±
    # DeepfakeDataset: real / fake / subset(train/val/test)
    # -------------------------------------------
    train_dataset = DeepfakeDataset(Config.DATA_DIR, subset='train')
    val_dataset   = DeepfakeDataset(Config.DATA_DIR, subset='val')

    train_loader = DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True,
        num_workers=args.num_workers
    )

    val_loader = DataLoader(
        val_dataset, batch_size=args.batch_size, shuffle=False,
        num_workers=args.num_workers
    ) 

    # --------------------------
    # ëª¨ë¸ ì„ íƒ
    # --------------------------
    if args.model == "beta_nll":
        model = DeepfakeUncertaintyModel().to(device)
        
        # ë¶„ë¥˜ìš© Loss (real/fake)
        bce_criterion  = nn.BCEWithLogitsLoss()
        # ë¶ˆí™•ì‹¤ì„±(Beta)ìš© Loss
        beta_criterion = Beta_NLL_Loss()
        
        beta_weight = 0.01   # Beta-NLLì„ ì–¼ë§ˆë‚˜ ì„ì„ì§€ ê°€ì¤‘ì¹˜ (í•„ìš”í•˜ë©´ íŠœë‹)
    else:
        raise NotImplementedError("MSE ëª¨ë¸ì€ ì•„ì§ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    # TensorBoard ì„¤ì •
    writer = SummaryWriter(f"{Config.LOG_DIR}/{args.model}")

    best_loss = float("inf")

    # --------------------------
    # Training Loop
    # --------------------------
    
    total_epochs = args.epochs
    epoch_times = []
    for epoch in range(args.epochs):
        print(f"\n[Epoch {epoch+1}/{args.epochs}]")

        epoch_start = time.time()   # <-- ì‹œì‘ ì‹œê°„ ì¸¡ì •

        train_loss = train_one_epoch(model, train_loader, bce_criterion, beta_criterion, optimizer, device, beta_weight=beta_weight,)
        val_loss, val_mae = validate(model, val_loader, bce_criterion, beta_criterion, device, beta_weight=beta_weight,)
        
        
        
        # --------------------------
        # Epoch ì¢…ë£Œ â†’ ì‹œê°„ ê³„ì‚°
        # --------------------------
        epoch_time = time.time() - epoch_start
        epoch_times.append(epoch_time)

        print(f"â±ï¸ ì´ë²ˆ Epoch ì†Œìš” ì‹œê°„: {format_time(epoch_time)}")

        # --------------------------
        # ETA ê³„ì‚° (í‰ê·  ì‹œê°„ ê¸°ë°˜)
        # --------------------------
        avg_time = sum(epoch_times) / len(epoch_times)
        remaining_epochs = total_epochs - (epoch + 1)
        eta = remaining_epochs * avg_time

        print(f"ğŸ”® ì˜ˆìƒ ë‚¨ì€ ì‹œê°„(ETA): {format_time(eta)}")

        # --------------------------
        # ë¡œê·¸ ì¶œë ¥
        # --------------------------
        print(f"Train Loss: {train_loss:.4f}")
        print(f"Val Loss:   {val_loss:.4f}")
        print(f"Val MAE:    {val_mae:.4f}")
        
        # TensorBoard ê¸°ë¡
        writer.add_scalar("Loss/train", train_loss, epoch)
        writer.add_scalar("Loss/val", val_loss, epoch)
        writer.add_scalar("MAE/val", val_mae, epoch)

        # --------------------------
        # Best Model ì €ì¥
        # --------------------------
        if val_loss < best_loss:
            best_loss = val_loss
            save_path = f"models/best_{args.model}_model.pth"
            save_checkpoint(model, save_path)

    writer.close()
    print("\n[Training Completed]")


if __name__ == "__main__":
    main()
